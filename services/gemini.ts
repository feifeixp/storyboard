
import { GoogleGenAI, Type, GenerateContentResponse } from "@google/genai";
import { Shot, ReviewSuggestion, CharacterRef } from "../types";
import type { ScriptAnalysis } from "../prompts/chain-of-thought/types";
import { buildStage1Prompt } from "../prompts/chain-of-thought/stage1-script-analysis";
import { extractJSON, mergeThinkingAndResult } from "../prompts/chain-of-thought/utils";

// æ”¯æŒä¸¤ç§ç¯å¢ƒï¼šVite (æµè§ˆå™¨) å’Œ Node.js (æµ‹è¯•)
const getApiKey = () => {
  // Vite ç¯å¢ƒ
  if (typeof import.meta !== 'undefined' && import.meta.env) {
    return import.meta.env.VITE_GEMINI_API_KEY;
  }
  // Node.js ç¯å¢ƒ
  return process.env.VITE_GEMINI_API_KEY;
};

const ai = new GoogleGenAI({ apiKey: getApiKey() });

// Helper to strip markdown code blocks
const cleanJsonOutput = (text: string): string => {
  return text.replace(/```json/g, '').replace(/```/g, '').trim();
};

// We keep a minimal "Role Definition" here, but the specific instructions will now come from the User Interface.
const BASE_ROLE_DEFINITION = `Role: AI æ¼«å‰§å¯¼æ¼” & æç¤ºè¯ä¸“å®¶. You are an expert in Cinematic Storytelling (Framed Ink).`;

export async function* generateShotListStream(script: string, customPrompt: string) {
  // Combine Role + User's Custom Instruction + Script
  const contentInput = `
  ${BASE_ROLE_DEFINITION}
  
  TASK INSTRUCTIONS (FROM USER):
  ${customPrompt}

  ----------------
  SOURCE SCRIPT:
  ${script}
  `;

  const stream = await ai.models.generateContentStream({
    model: 'gemini-3-flash-preview',
    contents: contentInput,
    config: {
      // systemInstruction: customPrompt, // We pass it in contents to ensure it's weighted heavily
      responseMimeType: "application/json",
      responseSchema: {
        type: Type.ARRAY,
        items: {
          type: Type.OBJECT,
          properties: {
            shotNumber: { type: Type.STRING },
            duration: { type: Type.STRING },
            visualDescription: { type: Type.STRING },
            dialogue: { type: Type.STRING },
            theory: { type: Type.STRING },
            refType: { type: Type.STRING },
            aiPromptEn: { type: Type.STRING },
            aiPromptCn: { type: Type.STRING },
            videoPromptEn: { type: Type.STRING },
            videoPromptCn: { type: Type.STRING },
            frameType: { type: Type.STRING, enum: ["å•é•œå¤´â†’[å•å¸§ç”Ÿæˆ]", "éœ€åŠ¨ç”»â†’[éœ€é¦–å°¾å¸§]"] }
          },
          required: ["shotNumber", "duration", "visualDescription", "dialogue", "theory", "aiPromptEn", "aiPromptCn", "frameType"]
        }
      }
    }
  });

  let fullText = "";
  for await (const chunk of stream) {
    fullText += chunk.text;
    yield fullText;
  }
}

export const reviewStoryboard = async (shots: Shot[], customCriteria: string): Promise<ReviewSuggestion[]> => {
  const contentInput = `
  Role: Lead Director / Script Doctor.
  
  YOUR REVIEW CRITERIA:
  ${customCriteria}

  Analyze the following storyboard data JSON and return a list of specific fix suggestions adhering to the criteria above.
  
  STORYBOARD DATA:
  ${JSON.stringify(shots)}
  `;

  const response = await ai.models.generateContent({
    model: 'gemini-3-flash-preview',
    contents: contentInput,
    config: {
      responseMimeType: "application/json",
      responseSchema: {
        type: Type.ARRAY,
        items: {
          type: Type.OBJECT,
          properties: {
            shotNumber: { type: Type.STRING },
            suggestion: { type: Type.STRING },
            reason: { type: Type.STRING }
          },
          required: ["shotNumber", "suggestion", "reason"]
        }
      }
    }
  });
  const text = cleanJsonOutput(response.text || '[]');
  return JSON.parse(text);
};

export async function* optimizeShotListStream(shots: Shot[], suggestions: ReviewSuggestion[]) {
  const prompt = `Task: Update storyboard JSON based on Director's Review.
  
  Strict Rules:
  - Apply the suggestions to 'visualDescription' and 'aiPromptEn'.
  - If angle changes, update the prompts.
  - Maintain the "Ink Sketch" style. NO realistic tags.
  - Return COMPLETE JSON.`;

  const stream = await ai.models.generateContentStream({
    model: 'gemini-3-flash-preview',
    contents: `${prompt}\n\nData: ${JSON.stringify(shots)}\nSuggestions: ${JSON.stringify(suggestions)}`,
    config: {
      responseMimeType: "application/json",
      responseSchema: {
        type: Type.ARRAY,
        items: {
          type: Type.OBJECT,
          properties: {
            shotNumber: { type: Type.STRING },
            duration: { type: Type.STRING },
            visualDescription: { type: Type.STRING },
            dialogue: { type: Type.STRING },
            theory: { type: Type.STRING },
            refType: { type: Type.STRING },
            aiPromptEn: { type: Type.STRING },
            aiPromptCn: { type: Type.STRING },
            videoPromptEn: { type: Type.STRING },
            videoPromptCn: { type: Type.STRING },
            frameType: { type: Type.STRING, enum: ["å•é•œå¤´â†’[å•å¸§ç”Ÿæˆ]", "éœ€åŠ¨ç”»â†’[éœ€é¦–å°¾å¸§]"] }
          },
          required: ["shotNumber", "duration", "visualDescription", "dialogue", "theory", "aiPromptEn", "aiPromptCn", "frameType"]
        }
      }
    }
  });

  let fullText = "";
  for await (const chunk of stream) {
    fullText += chunk.text;
    yield fullText;
  }
}

// NEW: Chat with Director (Conversational Text)
export async function* chatWithDirectorStream(history: {role: string, content: string}[], userInstruction: string) {
  const prompt = `You are an expert Storyboard Director (Framed Ink style). 
  The user is consulting you about the storyboard.
  
  Your Goal:
  1. Analyze the user's request.
  2. Provide professional advice based on Cinematic Theory (180 rule, composition, lighting).
  3. If the user asks to "Make it more dramatic", suggest specific Camera Angles (Dutch, Low, Extreme Close-up).
  4. Output natural language (Markdown allowed).
  
  Chat History:
  ${JSON.stringify(history)}
  
  User Input: "${userInstruction}"`;

  const stream = await ai.models.generateContentStream({
    model: 'gemini-3-flash-preview',
    contents: prompt,
  });

  for await (const chunk of stream) {
    yield chunk.text;
  }
}

// EXISTING: Update Shot List based on instructions (Execute)
export async function* chatEditShotListStream(shots: Shot[], userInstruction: string) {
  const prompt = `Task: AI Director Co-pilot. Modify storyboard based on user instruction.
  User Instruction: "${userInstruction}"
  
  Rules:
  - If user says "Too many frames" or "Simplify", change "frameType" of dialogue shots to "å•é•œå¤´â†’[å•å¸§ç”Ÿæˆ]".
  - Ensure updated prompts DO NOT contain realistic keywords like '8k'.
  - Maintain JSON structure.`;

  const stream = await ai.models.generateContentStream({
    model: 'gemini-3-flash-preview',
    contents: `${prompt}\n\nCurrent Storyboard: ${JSON.stringify(shots)}`,
    config: {
      responseMimeType: "application/json",
      responseSchema: {
        type: Type.ARRAY,
        items: {
          type: Type.OBJECT,
          properties: {
            shotNumber: { type: Type.STRING },
            duration: { type: Type.STRING },
            visualDescription: { type: Type.STRING },
            dialogue: { type: Type.STRING },
            theory: { type: Type.STRING },
            refType: { type: Type.STRING },
            aiPromptEn: { type: Type.STRING },
            aiPromptCn: { type: Type.STRING },
            videoPromptEn: { type: Type.STRING },
            videoPromptCn: { type: Type.STRING },
            frameType: { type: Type.STRING, enum: ["å•é•œå¤´â†’[å•å¸§ç”Ÿæˆ]", "éœ€åŠ¨ç”»â†’[éœ€é¦–å°¾å¸§]"] }
          },
          required: ["shotNumber", "duration", "visualDescription", "dialogue", "theory", "aiPromptEn", "aiPromptCn", "frameType"]
        }
      }
    }
  });

  let fullText = "";
  for await (const chunk of stream) {
    fullText += chunk.text;
    yield fullText;
  }
}

export const generateMergedStoryboardSheet = async (
  shots: Shot[],
  characterRefs: CharacterRef[],
  mode: 'draft' | 'hq'
): Promise<string[]> => {
  
  const charContext = characterRefs.length > 0 
    ? `Character details: ${characterRefs.map(c => c.name).join(', ')}. ` 
    : '';
  
  const isDraft = mode === 'draft';

  // 1. EXPAND shots into render panels
  const renderPanels: any[] = [];
  shots.forEach(s => {
    // Extract Shot Type from promptEn
    const shotTypeMatch = s.promptEn?.match(/^\((.*?)\)/);
    const shotType = shotTypeMatch ? `(${shotTypeMatch[1]})` : '';

    // ğŸ”§ ä¿®å¤ï¼šæ”¯æŒ storyBeat çš„ä¸¤ç§ç±»å‹
    const storyBeatText = typeof s.storyBeat === 'string'
      ? s.storyBeat
      : (s.storyBeat?.event || '');
    const shortVisual = storyBeatText.replace(/ã€.*?ã€‘/g, '').replace(/\n/g, ' ').substring(0, 8) || '';
    const dialogueClean = s.dialogue ? `\nå¯¹: ${s.dialogue.substring(0, 10)}` : '';

    let cleanAiPrompt = s.promptEn || s.imagePromptEn || '';

    // åˆ¤æ–­æ˜¯å¦éœ€è¦é¦–å°¾å¸§ï¼ˆè¿åŠ¨é•œå¤´ï¼‰
    if (s.shotType === 'è¿åŠ¨' && s.startFrame && s.endFrame) {
      renderPanels.push({
        id: `${s.shotNumber}a`,
        caption: `${s.shotNumber}a (é¦–) ${shortVisual} ${shotType}${dialogueClean}`,
        prompt: `Panel ${s.shotNumber}a (Start): ${cleanAiPrompt}`
      });
      renderPanels.push({
        id: `${s.shotNumber}b`,
        caption: `${s.shotNumber}b (å°¾) ${shortVisual} ${shotType}${dialogueClean}`,
        prompt: `Panel ${s.shotNumber}b (End): ${cleanAiPrompt}`
      });
    } else {
      renderPanels.push({
        id: s.shotNumber,
        caption: `${s.shotNumber} (å•) ${shortVisual} ${shotType}${dialogueClean}`,
        prompt: `Panel ${s.shotNumber}: ${cleanAiPrompt}`
      });
    }
  });

  // 2. SINGLE SHEET LOGIC
  // We want ONE sheet containing ALL panels.
  const totalPanels = renderPanels.length;
  // Fixed 4 columns is standard for vertical cinematic sheets
  const COLUMNS = 4;
  const ROWS = Math.ceil(totalPanels / COLUMNS);
  
  const sequenceDescription = renderPanels.map(p => 
    `${p.prompt}\n[CAPTION]: "${p.caption}"`
  ).join('\n\n');

  const styleInstruction = "Style: Professional Manga Storyboard. Hand-drawn ink sketch. Black and white. High contrast. Rough, loose lines. NO color. NO photorealism.";

  const layoutInstruction = `LAYOUT COMMAND:
      - Draw a SINGLE grid of ${COLUMNS} columns x ${ROWS} rows.
      - Total Panels to draw: ${totalPanels}.
      - Aspect Ratio of entire sheet: Vertical (9:16).
      - IMPORTANT: Below EACH panel, you MUST render the [CAPTION] text cleanly in SIMPLIFIED CHINESE.
      - The text must be legible black ink. 
      - Do NOT split into multiple images. Output one tall image.`;

  const fullPrompt = `${charContext}
  Create the COMPLETE Storyboard Sheet.
  ${styleInstruction}
  ${layoutInstruction}
  
  Panels to populate in the grid:
  ${sequenceDescription}
  
  Output ONE single vertical image containing all these panels.`;
  
  const parts: any[] = [{ text: fullPrompt }];
  characterRefs.forEach(ref => {
    parts.push({
      inlineData: {
        data: ref.data.split(',')[1],
        mimeType: 'image/png'
      }
    });
  });

  try {
    const model = 'gemini-3-pro-image-preview';
    
    const config: any = {
      imageConfig: {
          aspectRatio: "9:16", // Vertical Long for single sheet
          imageSize: isDraft ? "1K" : "2K" 
      }
    };

    const response = await ai.models.generateContent({
      model: model, 
      contents: { parts },
      config: config
    });

    for (const part of response.candidates?.[0]?.content?.parts || []) {
      if (part.inlineData) {
        return [`data:image/png;base64,${part.inlineData.data}`]; // Return as array for compatibility
      }
    }
    return [];
  } catch (e) {
    console.error(`Generation failed`, e);
    return [];
  }
}

// ============================================
// æ€ç»´é“¾ç”Ÿæˆå‡½æ•°
// ============================================

/**
 * é˜¶æ®µ1ï¼šå‰§æœ¬åˆ†æï¼ˆæ€ç»´é“¾æ¨¡å¼ï¼‰
 * ä½¿ç”¨ Gemini 2.0 Flash Thinking æ¨¡å‹
 */
export async function* generateStage1Analysis(script: string) {
  const prompt = buildStage1Prompt(script);

  try {
    console.log('[DEBUG] å¼€å§‹è°ƒç”¨ Gemini API...');
    console.log('[DEBUG] æç¤ºè¯é•¿åº¦:', prompt.length, 'å­—ç¬¦');

    // ä½¿ç”¨æ€ç»´é“¾ä¸“ç”¨æ¨¡å‹ï¼ˆå¦‚æœä¸å¯ç”¨ï¼Œä¼šè‡ªåŠ¨é™çº§åˆ° gemini-2.0-flash-expï¼‰
    const modelName = 'gemini-2.0-flash-thinking-exp-1219';
    console.log('[DEBUG] ä½¿ç”¨æ¨¡å‹:', modelName);

    const stream = await ai.models.generateContentStream({
      model: modelName,
      contents: prompt,
      config: {
        temperature: 0.7,
        topP: 0.9,
        maxOutputTokens: 8192,
        // ä¸ä½¿ç”¨ JSON schemaï¼Œè®©æ¨¡å‹è‡ªç”±è¾“å‡ºæ€è€ƒè¿‡ç¨‹
        responseMimeType: "text/plain"
      }
    });

    console.log('[DEBUG] API è°ƒç”¨æˆåŠŸï¼Œå¼€å§‹æ¥æ”¶æµå¼æ•°æ®...\n');

    let fullText = '';
    for await (const chunk of stream) {
      // chunk.text å¯èƒ½æ˜¯æ–¹æ³•æˆ–å±æ€§ï¼Œæ ¹æ® Gemini SDK ç‰ˆæœ¬è€Œå®š
      const text = (chunk as any).text?.() ?? (chunk as any).text ?? '';
      fullText += text;
      yield text; // æµå¼è¾“å‡º
    }

    console.log('\n[DEBUG] æµå¼æ•°æ®æ¥æ”¶å®Œæˆï¼Œæ€»é•¿åº¦:', fullText.length, 'å­—ç¬¦');

    // è¿”å›å®Œæ•´æ–‡æœ¬ç”¨äºåç»­å¤„ç†
    return fullText;
  } catch (error) {
    console.error('[ERROR] é˜¶æ®µ1ç”Ÿæˆå¤±è´¥:', error);
    if (error instanceof Error) {
      console.error('[ERROR] é”™è¯¯ä¿¡æ¯:', error.message);
      console.error('[ERROR] é”™è¯¯å †æ ˆ:', error.stack);
    }
    throw error;
  }
}

/**
 * è§£æé˜¶æ®µ1çš„è¾“å‡º
 */
export function parseStage1Output(fullText: string): ScriptAnalysis {
  try {
    // ä½¿ç”¨å·¥å…·å‡½æ•°æå–JSONå’Œæ€è€ƒè¿‡ç¨‹
    const result = mergeThinkingAndResult<ScriptAnalysis>(
      fullText,
      ['basicInfo', 'emotionArc', 'climax', 'conflict', 'scenes']
    );

    return result;
  } catch (error) {
    console.error('è§£æé˜¶æ®µ1è¾“å‡ºå¤±è´¥:', error);
    throw new Error(`æ— æ³•è§£æå‰§æœ¬åˆ†æç»“æœ: ${error instanceof Error ? error.message : 'æœªçŸ¥é”™è¯¯'}`);
  }
}
